
Building a predictive model using linear regression involves the following steps:

Load and Explore the Data: Understand the dataset and its structure.
Preprocess the Data: Handle missing values, encode categorical variables, and split the data into training and testing sets.
Train the Linear Regression Model: Fit the model to the training data.
Evaluate the Model: Assess the performance of the model using appropriate metrics.
Make Predictions: Use the model to make predictions on new data.
We'll use the popular Boston Housing Dataset from the sklearn library for this example.

Step-by-Step Implementation
Step 1: Import Libraries
First, we need to import the necessary libraries.

python
Copy code
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.datasets import load_boston
import seaborn as sns

# Load the dataset
boston = load_boston()
Step 2: Load and Explore the Data
python
Copy code
# Convert the dataset to a pandas DataFrame
df = pd.DataFrame(boston.data, columns=boston.feature_names)
df['MEDV'] = boston.target

# Display the first few rows of the dataframe
df.head()
Step 3: Preprocess the Data
We need to handle any missing values, encode categorical variables if any, and split the data into training and testing sets.

python
Copy code
# Check for missing values
df.isnull().sum()

# Split the data into training and testing sets
X = df.drop('MEDV', axis=1)
y = df['MEDV']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
Step 4: Train the Linear Regression Model
python
Copy code
# Initialize the model
model = LinearRegression()

# Train the model
model.fit(X_train, y_train)
Step 5: Evaluate the Model
We will use Mean Squared Error (MSE) and R-squared as the evaluation metrics.

python
Copy code
# Make predictions on the testing set
y_pred = model.predict(X_test)

# Calculate the mean squared error
mse = mean_squared_error(y_test, y_pred)

# Calculate the R-squared value
r2 = r2_score(y_test, y_pred)

print(f'Mean Squared Error: {mse}')
print(f'R-squared: {r2}')
Step 6: Make Predictions
We can now use the trained model to make predictions on new data.

python
Copy code
# Example: Predicting the price of a house with given features
new_data = [[0.00632, 18.00, 2.31, 0, 0.5380, 6.5750, 65.20, 4.0900, 1, 296.0, 15.30, 396.90, 4.98]]
predicted_price = model.predict(new_data)
print(f'Predicted Price: {predicted_price[0]}')
Full Jupyter Notebook Code
python
Copy code
# Import libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.datasets import load_boston
import seaborn as sns

# Load the dataset
boston = load_boston()

# Convert the dataset to a pandas DataFrame
df = pd.DataFrame(boston.data, columns=boston.feature_names)
df['MEDV'] = boston.target

# Display the first few rows of the dataframe
print(df.head())

# Check for missing values
print(df.isnull().sum())

# Split the data into training and testing sets
X = df.drop('MEDV', axis=1)
y = df['MEDV']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize the model
model = LinearRegression()

# Train the model
model.fit(X_train, y_train)

# Make predictions on the testing set
y_pred = model.predict(X_test)

# Calculate the mean squared error
mse = mean_squared_error(y_test, y_pred)
print(f'Mean Squared Error: {mse}')

# Calculate the R-squared value
r2 = r2_score(y_test, y_pred)
print(f'R-squared: {r2}')

# Plot the true values vs. the predicted values
plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred, edgecolors=(0, 0, 0))
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linewidth=2)
plt.xlabel('Actual')
plt.ylabel('Predicted')
plt.title('Actual vs Predicted')
plt.show()

# Example: Predicting the price of a house with given features
new_data = [[0.00632, 18.00, 2.31, 0, 0.5380, 6.5750, 65.20, 4.0900, 1, 296.0, 15.30, 396.90, 4.98]]
predicted_price = model.predict(new_data)
print(f'Predicted Price: {predicted_price[0]}')
This code demonstrates a complete process for building a predictive model using linear regression to predict housing prices based on various features in the Boston Housing Dataset. You can modify and expand this approach to fit different datasets and prediction tasks.








